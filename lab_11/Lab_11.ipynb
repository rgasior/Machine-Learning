{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0802656",
   "metadata": {},
   "source": [
    "Lab_11\n",
    "Rafał Gąsior 407326"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff909c70",
   "metadata": {},
   "source": [
    "### Klasyfikacja z wykorzystaniem sieci neuronowych\n",
    "W ramach tego ćwiczenia zadaniem będzie przeprowadzenie eksperymentu mającego na celu wytrenowanie modelu do klasyfikacji odręcznie pisanych cyfr z bazy MNIST. Jako klasyfikator należy zastosować każdy z trzech typów: pojedynczy neuron, sieć neuronowa MLP oraz sieć konwolucyjna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c0f9795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d54901",
   "metadata": {},
   "source": [
    "#### Wczytywanie i konwersja danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b42a3b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, test_set = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca745d",
   "metadata": {},
   "source": [
    "Dla wygody, warto podzielić zbiór danych na przykłady oraz etykiety:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31189c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = training_set\n",
    "X_test, y_test = test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d58047",
   "metadata": {},
   "source": [
    "Po wypisaniu wymiaru wczytanych danych, możemy się spodziewać wartości:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21947502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdaf1f1",
   "metadata": {},
   "source": [
    "Co oznacza, że tensor ma 3 wymiary i każdy z nich jest reprezentowany przez:\n",
    "- ilość przykładów,\n",
    "- wysokość obrazu,\n",
    "- szerokość obrazu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344dca49",
   "metadata": {},
   "source": [
    "Tensorflow przyjmuje dane w postaci obrazów z jeszcze jednym dodatkowym wymiarem na końcu - liczbą kanałów (w przypadku obrazów w skali szarości jest to 1 kanał, dla obrazów RGB - 3 kanału). Należy dodać wymiar kanału do zbioru uczącego i testowego: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6c10d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0db22a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11396521",
   "metadata": {},
   "source": [
    "W ostatnim kroku, wartości pikseli warto przeskalować do zakresu 0.0-1.0. Obraz jest w skali szarości, gdzie wartość pikseli jest reprezentowana na ośmiu bitach, dlatego też wystarczy podzielić każdy z pikseli przez maksymalną możliwą wartość, tj 255: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b6ebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float) / 255.0  \n",
    "X_test = X_test.astype(np.float) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac768e5",
   "metadata": {},
   "source": [
    "#### Przygotowanie eksperymentu\n",
    "Kilka wartości definiujących warunki eksperymentu: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "962041fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "batch_size = 128\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2d6168",
   "metadata": {},
   "source": [
    "gdzie każda z nich oznacza:\n",
    "num_classes - ilość klas do klasyfikacji (w tym przypadku 10 gdyż klasyfikujemy cyfry 0-9),\n",
    "input_shape - rozmiar wejścia na sieć (obraz w skali szarości z jednym kanałem),\n",
    "batch_size - rozmiar paczki będącej jednorazowym wejściem na sieć (z reguły sieci nie trenuje się na wszystkich danych na raz, m. in. z powodu ograniczeń pamięci dla obszernych danych),\n",
    "epochs - ilość epok uczenia. Jako jedną epokę interpretujemy “pokazanie” wszystkich przykładów modelowi.\n",
    "\n",
    "Następnie należy przygotować model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9beb2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef84ded3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            keras.layers.Flatten(),\n",
    "            layers.Dense(num_classes, activation=\"softmax\")\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbb201c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2582a3",
   "metadata": {},
   "source": [
    "Kompilowanie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a1fe374",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f40627",
   "metadata": {},
   "source": [
    "Powyższy kod utworzy model sekwencyjny (bez rozgałęzień) składający się z warstwy wejściowej, warstwy rozplatającej obraz z macierzy HxWxD na wektor jednowymiarowy o długości H*W*D, oraz warstwy gęstej reprezentowanej przez jeden neuron dla każdej z klas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da674fc",
   "metadata": {},
   "source": [
    "### Uczenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0feb0f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7439 - accuracy: 0.8231 - val_loss: 0.4071 - val_accuracy: 0.8985\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.3880 - accuracy: 0.8982 - val_loss: 0.3337 - val_accuracy: 0.9104\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.9081 - val_loss: 0.3076 - val_accuracy: 0.9148\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3142 - accuracy: 0.9132 - val_loss: 0.2940 - val_accuracy: 0.9187\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3003 - accuracy: 0.9170 - val_loss: 0.2840 - val_accuracy: 0.9227\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2908 - accuracy: 0.9193 - val_loss: 0.2785 - val_accuracy: 0.9229\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2836 - accuracy: 0.9215 - val_loss: 0.2745 - val_accuracy: 0.9226\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2784 - accuracy: 0.9232 - val_loss: 0.2716 - val_accuracy: 0.9259\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2734 - accuracy: 0.9242 - val_loss: 0.2704 - val_accuracy: 0.9256\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2698 - accuracy: 0.9248 - val_loss: 0.2680 - val_accuracy: 0.9266\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2668 - accuracy: 0.9259 - val_loss: 0.2659 - val_accuracy: 0.9274\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2639 - accuracy: 0.9264 - val_loss: 0.2658 - val_accuracy: 0.9268\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2622 - accuracy: 0.9269 - val_loss: 0.2634 - val_accuracy: 0.9282\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2595 - accuracy: 0.9274 - val_loss: 0.2622 - val_accuracy: 0.9277\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2577 - accuracy: 0.9279 - val_loss: 0.2636 - val_accuracy: 0.9284\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2563 - accuracy: 0.9282 - val_loss: 0.2612 - val_accuracy: 0.9284\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2543 - accuracy: 0.9287 - val_loss: 0.2606 - val_accuracy: 0.9302\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2528 - accuracy: 0.9293 - val_loss: 0.2601 - val_accuracy: 0.9300\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2517 - accuracy: 0.9296 - val_loss: 0.2588 - val_accuracy: 0.9300\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.9297 - val_loss: 0.2593 - val_accuracy: 0.9295\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.9309 - val_loss: 0.2596 - val_accuracy: 0.9297\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.9302 - val_loss: 0.2601 - val_accuracy: 0.9298\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2474 - accuracy: 0.9309 - val_loss: 0.2586 - val_accuracy: 0.9303\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.9313 - val_loss: 0.2588 - val_accuracy: 0.9300\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.9323 - val_loss: 0.2578 - val_accuracy: 0.9314\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.9320 - val_loss: 0.2581 - val_accuracy: 0.9312\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.9318 - val_loss: 0.2613 - val_accuracy: 0.9289\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2430 - accuracy: 0.9325 - val_loss: 0.2606 - val_accuracy: 0.9308\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2423 - accuracy: 0.9326 - val_loss: 0.2597 - val_accuracy: 0.9304\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2416 - accuracy: 0.9332 - val_loss: 0.2607 - val_accuracy: 0.9294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a79f335580>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3906c78e",
   "metadata": {},
   "source": [
    "Spodziewamy się spadku wartości funkcji kosztu (loss) oraz wzrostu metryki accuracy z epoki na epokę na zbiorze uczącym i walidacyjnym. Ilość epok staramy się tak dobrać aby otrzymać jak najniższe wartości kosztu (loss oraz val_loss) na obu zbiorach. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3170be",
   "metadata": {},
   "source": [
    "### Ocena modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a320947",
   "metadata": {},
   "source": [
    "Do oceny modelu klasyfikacji głównie stosuje się metryki czułości (sensitivity, recall) oraz pozytywnego przewidywania (positive predictivity, precision) oraz ich średnią harmoniczną (F1-score). Aby policzyć metryki można użyć wbudowanych w bibliotekę sciki t-learn funkcji: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "704103b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e30021",
   "metadata": {},
   "source": [
    "Przed ich użyciem należy wygenerować odpowiedzi modelu na zbiorze testowym: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee9bf925",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probab = model.predict(X_test)\n",
    "y_pred = np.argmax(y_probab, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fd1dc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       980\n",
      "           1       0.97      0.98      0.97      1135\n",
      "           2       0.93      0.89      0.91      1032\n",
      "           3       0.91      0.91      0.91      1010\n",
      "           4       0.94      0.93      0.93       982\n",
      "           5       0.92      0.87      0.89       892\n",
      "           6       0.94      0.96      0.95       958\n",
      "           7       0.92      0.93      0.92      1028\n",
      "           8       0.86      0.91      0.88       974\n",
      "           9       0.92      0.90      0.91      1009\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "[[ 947    0    2    2    1    6   14    4    4    0]\n",
      " [   0 1113    3    3    0    1    3    2   10    0]\n",
      " [   3   11  922   15    8    4   12   10   44    3]\n",
      " [   2    0   18  920    0   23    2   12   27    6]\n",
      " [   1    2    7    1  914    0    8    7   10   32]\n",
      " [   6    2    3   35    8  773   15    8   36    6]\n",
      " [   8    3    8    1    7   11  917    1    2    0]\n",
      " [   1    7   22    7    5    0    0  959    2   25]\n",
      " [   4    8    5   17    7   19    9   12  888    5]\n",
      " [   9    7    1    9   24    6    0   31   10  912]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d061ff72",
   "metadata": {},
   "source": [
    "### Uczenie modeli nieliniowych\n",
    "Należy powtórzyć eksperyment dla modelu MLP oraz sieci konwolucyjnej. Sieć MLP powinna składać się z dwóch ukrytych warstw Dense, natomiast sieć konwolucyjna naprzemiennie z warstw konwolucyjnych oraz maxpooling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950834fc",
   "metadata": {},
   "source": [
    "### Model MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6eda3e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MLP = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            keras.layers.Flatten(),\n",
    "            layers.Dense(64, activation=\"tanh\"),\n",
    "            layers.Dense(128, activation=\"tanh\"),\n",
    "            layers.Dense(num_classes, activation=\"softmax\")\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2431eb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 59,850\n",
      "Trainable params: 59,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_MLP.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51589d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MLP.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d51e99",
   "metadata": {},
   "source": [
    "Uczenie modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6f52607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4048 - accuracy: 0.8849 - val_loss: 0.2187 - val_accuracy: 0.9380\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1925 - accuracy: 0.9429 - val_loss: 0.1637 - val_accuracy: 0.9535\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1396 - accuracy: 0.9582 - val_loss: 0.1307 - val_accuracy: 0.9617\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1079 - accuracy: 0.9672 - val_loss: 0.1213 - val_accuracy: 0.9641\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0869 - accuracy: 0.9740 - val_loss: 0.1060 - val_accuracy: 0.9678\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0713 - accuracy: 0.9784 - val_loss: 0.1029 - val_accuracy: 0.9694\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0601 - accuracy: 0.9818 - val_loss: 0.1015 - val_accuracy: 0.9699\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0509 - accuracy: 0.9840 - val_loss: 0.0977 - val_accuracy: 0.9714\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0421 - accuracy: 0.9867 - val_loss: 0.0951 - val_accuracy: 0.9718\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0352 - accuracy: 0.9892 - val_loss: 0.0993 - val_accuracy: 0.9722\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0283 - accuracy: 0.9916 - val_loss: 0.0982 - val_accuracy: 0.9736\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9937 - val_loss: 0.1016 - val_accuracy: 0.9722\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.1139 - val_accuracy: 0.9700\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.1068 - val_accuracy: 0.9711\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0134 - accuracy: 0.9966 - val_loss: 0.1087 - val_accuracy: 0.9722\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.1102 - val_accuracy: 0.9721\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.1120 - val_accuracy: 0.9723\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.1285 - val_accuracy: 0.9697\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.1288 - val_accuracy: 0.9706\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.1267 - val_accuracy: 0.9725\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.1163 - val_accuracy: 0.9732\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.1414 - val_accuracy: 0.9707\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.1387 - val_accuracy: 0.9698\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.1476 - val_accuracy: 0.9697\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.1260 - val_accuracy: 0.9736\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.1301 - val_accuracy: 0.9747\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.1362 - val_accuracy: 0.9729\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 7.7599e-04 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9742\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.8243e-04 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9745\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.6583e-04 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a7b09cdac0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_MLP.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "971d8f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probab = model_MLP.predict(X_test)\n",
    "y_pred = np.argmax(y_probab, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f92e4383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.96      0.98      0.97      1032\n",
      "           3       0.96      0.98      0.97      1010\n",
      "           4       0.98      0.97      0.98       982\n",
      "           5       0.98      0.96      0.97       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.97      0.97      0.97      1028\n",
      "           8       0.97      0.97      0.97       974\n",
      "           9       0.97      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.97      0.97     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n",
      "[[ 971    1    2    0    0    1    3    1    0    1]\n",
      " [   0 1123    4    0    0    2    2    1    3    0]\n",
      " [   5    0 1008    6    0    0    2    3    6    2]\n",
      " [   0    0    6  987    1    3    0    4    5    4]\n",
      " [   0    1    3    3  953    0    7    2    2   11]\n",
      " [   3    1    2   14    2  858    4    1    4    3]\n",
      " [   1    2    7    0    5    5  936    0    2    0]\n",
      " [   0    7   10    4    2    0    0  996    3    6]\n",
      " [   3    0    4    8    3    5    1    6  941    3]\n",
      " [   1    2    0    7    5    5    0    8    3  978]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecb385e",
   "metadata": {},
   "source": [
    "### Model sieci konwolucyjnej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff7ee086",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_konw = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6dd42816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_konw.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a4c75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_konw.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679c4695",
   "metadata": {},
   "source": [
    "Uczenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ec5227f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "375/375 [==============================] - 19s 50ms/step - loss: 0.3929 - accuracy: 0.8803 - val_loss: 0.1059 - val_accuracy: 0.9707\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 0.1219 - accuracy: 0.9624 - val_loss: 0.0702 - val_accuracy: 0.9798\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 0.0916 - accuracy: 0.9717 - val_loss: 0.0582 - val_accuracy: 0.9837\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.0744 - accuracy: 0.9772 - val_loss: 0.0519 - val_accuracy: 0.9843\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 19s 50ms/step - loss: 0.0660 - accuracy: 0.9800 - val_loss: 0.0468 - val_accuracy: 0.9860\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 0.0578 - accuracy: 0.9823 - val_loss: 0.0420 - val_accuracy: 0.9875\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.0545 - accuracy: 0.9829 - val_loss: 0.0389 - val_accuracy: 0.9883\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 22s 57ms/step - loss: 0.0487 - accuracy: 0.9850 - val_loss: 0.0381 - val_accuracy: 0.9887\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.0477 - accuracy: 0.9850 - val_loss: 0.0367 - val_accuracy: 0.9900\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.0424 - accuracy: 0.9865 - val_loss: 0.0347 - val_accuracy: 0.9893\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.0406 - accuracy: 0.9869 - val_loss: 0.0339 - val_accuracy: 0.9894\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 22s 57ms/step - loss: 0.0379 - accuracy: 0.9883 - val_loss: 0.0337 - val_accuracy: 0.9904\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 22s 57ms/step - loss: 0.0378 - accuracy: 0.9876 - val_loss: 0.0317 - val_accuracy: 0.9899\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.0345 - accuracy: 0.9891 - val_loss: 0.0308 - val_accuracy: 0.9909\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.0347 - accuracy: 0.9886 - val_loss: 0.0321 - val_accuracy: 0.9907\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.0327 - accuracy: 0.9895 - val_loss: 0.0324 - val_accuracy: 0.9903\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.0309 - accuracy: 0.9899 - val_loss: 0.0318 - val_accuracy: 0.9909\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 0.0292 - val_accuracy: 0.9918\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.0300 - accuracy: 0.9898 - val_loss: 0.0278 - val_accuracy: 0.9920\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.0270 - accuracy: 0.9912 - val_loss: 0.0295 - val_accuracy: 0.9911\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.0272 - accuracy: 0.9904 - val_loss: 0.0298 - val_accuracy: 0.9924\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 0.0305 - val_accuracy: 0.9917\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.0263 - accuracy: 0.9912 - val_loss: 0.0280 - val_accuracy: 0.9923\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.0274 - val_accuracy: 0.9926\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.0246 - accuracy: 0.9916 - val_loss: 0.0278 - val_accuracy: 0.9919\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.0264 - val_accuracy: 0.9928\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.0281 - val_accuracy: 0.9918\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.0276 - val_accuracy: 0.9927\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 0.0281 - val_accuracy: 0.9925\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 0.0297 - val_accuracy: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a7b0e15a00>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_konw.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c111eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probab = model_konw.predict(X_test)\n",
    "y_pred = np.argmax(y_probab, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f20299f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       980\n",
      "           1       0.99      1.00      0.99      1135\n",
      "           2       0.99      0.99      0.99      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       0.99      0.99      0.99       982\n",
      "           5       0.99      0.99      0.99       892\n",
      "           6       1.00      0.99      0.99       958\n",
      "           7       0.98      0.99      0.99      1028\n",
      "           8       0.99      0.99      0.99       974\n",
      "           9       0.99      0.98      0.99      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n",
      "[[ 978    0    0    0    0    0    0    1    1    0]\n",
      " [   0 1132    2    1    0    0    0    0    0    0]\n",
      " [   1    2 1023    0    1    0    0    4    1    0]\n",
      " [   0    0    2 1002    0    4    0    1    1    0]\n",
      " [   0    2    1    0  973    0    1    1    1    3]\n",
      " [   0    0    0    4    0  885    1    1    1    0]\n",
      " [   1    2    2    0    1    2  948    0    2    0]\n",
      " [   0    3    5    0    0    1    0 1018    1    0]\n",
      " [   1    0    1    1    0    1    0    3  965    2]\n",
      " [   2    3    1    0    3    2    0    5    1  992]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242de1ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
